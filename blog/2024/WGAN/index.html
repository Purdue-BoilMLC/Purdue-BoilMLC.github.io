<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Understanding Wasserstein GANs: A Mathematical Perspective | Boilermakers Machine Learning Collaborative (Boil-MLC) | Students Machine Learning Seminar at Purdue University </title> <meta name="author" content=" "> <meta name="description" content="A paper review on &lt;a href=https://arxiv.org/pdf/1701.07875&gt;Wasserstein GAN&lt;/a&gt;"> <meta name="keywords" content="Machine Learning, Interdisciplinary Collaboration, Academic Initiative, PhD Students, Research, Innovation, Workshops, Seminars, Purdue University, Computer Science, Mathematics, Statistics"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/u1f525_u1f95b.png?ccae948c32cbc6d3f1ace744c1e8707b"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://purdue-boilmlc.github.io/blog/2024/WGAN/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Understanding Wasserstein GANs: A Mathematical Perspective",
            "description": "A paper review on <a href=https://arxiv.org/pdf/1701.07875>Wasserstein GAN</a>",
            "published": "June 24, 2024",
            "authors": [
              
              {
                "author": "Yuetian Chen",
                "authorURL": "https://stry233.github.io/",
                "affiliations": [
                  {
                    "name": "TruSeLab, Purdue University",
                    "url": "https://www.cs.purdue.edu/truselab/"
                  }
                ]
              },
              
              {
                "author": "Yineng Chen",
                "authorURL": "https://chernyn.github.io/",
                "affiliations": [
                  {
                    "name": "Purdue University",
                    "url": "https://www.purdue.edu"
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter abbr-title" href="/"> <img src="/assets/img/u1f525_u1f95b.png" alt="Logo" style="height: 30px; vertical-align: middle; margin-right: 5px; position: relative; top: -2.5px;">Boil-MLC </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Articles </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Events </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">People </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Understanding Wasserstein GANs: A Mathematical Perspective</h1> <p>A paper review on <a href="https://arxiv.org/pdf/1701.07875" rel="external nofollow noopener" target="_blank">Wasserstein GAN</a></p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#introduction">Introduction</a> </div> <div> <a href="#scaling-language-models">Scaling Language Models</a> </div> <ul> <li> <a href="#the-gopher-architecture">The Gopher Architecture</a> </li> <li> <a href="#key-insights-from-gopher">Key Insights from Gopher</a> </li> </ul> <div> <a href="#conclusion">Conclusion</a> </div> </nav> </d-contents> <h2 id="introduction">Introduction</h2> <p>Generative Adversarial Networks (GANs)<d-cite key="goodfellow2014generative"></d-cite> have revolutionized the field of generative modeling by enabling the creation of highly realistic images, videos, and other media. Despite their success, standard GANs frequently face significant training challenges, such as instability, mode collapse, and difficulties in achieving convergence. These issues often stem from the choice of divergence metrics used to measure the difference between real and generated data distributions.</p> <p>In this blog post, we explore how Wasserstein GANs (WGANs)<d-cite key="arjovsky2017wasserstein"></d-cite> address these challenges by leveraging the Wasserstein distance, leading to more stable training and superior generative performance. We delve into the mathematical foundations of WGANs, discuss their improvements over standard GANs, and examine their practical implications.</p> <h2 id="overcoming-challenges-in-standard-gans">Overcoming Challenges in Standard GANs</h2> <p>Standard GANs consist of two neural networks—the generator (G) and the discriminator (D)—engaged in a minimax game. The generator aims to create samples indistinguishable from real data, while the discriminator strives to differentiate between real and generated samples. The loss functions for the generator and discriminator can be expressed as:</p> \[\label{eq:gan_loss} \begin{aligned} \min_G \max_D &amp; \, \mathbb{E}_{x \sim P_r} [\log D(x)] + \mathbb{E}_{\hat{x} \sim P_g} [\log (1 - D(\hat{x}) )], \end{aligned}\] <p>where \(P_r\) denotes the real data distribution, and \(P_g\) is the distribution induced by the generator over the data space.</p> <h3 id="common-issues-in-standard-gan-training">Common Issues in Standard GAN Training</h3> <ol> <li> <strong>Mode Collapse</strong>: The generator produces a limited diversity of samples, causing it to capture only a few modes of the real data distribution.</li> <li> <strong>Training Instability</strong>: The adversarial nature of the GAN training often leads to oscillations and lack of convergence.</li> <li> <strong>Vanishing Gradients</strong>: When the discriminator becomes too effective, the generator receives negligible gradient updates, hindering its improvement.</li> </ol> <p>These problems largely arise from the nature of the Jensen-Shannon (JS) divergence used in standard GANs. When the supports of \(P_r\) and \(P_g\) do not overlap, the JS divergence becomes constant, leading to vanishing gradients.</p> <h2 id="the-wasserstein-distance">The Wasserstein Distance</h2> <p>Wasserstein GANs propose an elegant solution by replacing the JS divergence with the Wasserstein distance (also known as the Earth Mover’s distance), which measures the cost of transforming one distribution into another. This metric remains meaningful even when the distributions have non-overlapping supports.</p> <h3 id="mathematical-formulation">Mathematical Formulation</h3> <p>The Wasserstein distance between two probability distributions \(P_r\) and \(P_g\) is defined as:</p> \[\label{eq:wasserstein} W(P_r, P_g) = \inf_{\gamma \in \Pi(P_r, P_g)} \mathbb{E}_{(x, y) \sim \gamma}[\|x - y\|],\] <p>where \(\Pi(P_r, P_g)\) is the set of all joint distributions \(\gamma(x, y)\) whose marginals are \(P_r\) and \(P_g\), respectively. Intuitively, it represents the minimum amount of “work” needed to transform \(P_g\) into \(P_r\), considering the cost of moving mass from point \(x\) to \(y\).</p> <h3 id="kantorovich-rubinstein-duality">Kantorovich-Rubinstein Duality</h3> <p>In practice, directly computing the Wasserstein distance is intractable. Instead, the problem can be reformulated using Kantorovich-Rubinstein duality<d-cite key="villani2009optimal"></d-cite>:</p> \[\label{eq:kantorovich} W(P_r, P_g) = \sup_{\|f\|_L \leq 1} \mathbb{E}_{x \sim P_r}[f(x)] - \mathbb{E}_{x \sim P_g}[f(x)],\] <p>where the supremum is over all 1-Lipschitz functions \(f\).</p> <p>In the context of WGANs, the discriminator \(D\) is used to approximate the optimal 1-Lipschitz function \(f\). Thus, the loss functions for the generator and discriminator can be written as:</p> \[\label{eq:wgan_loss} \begin{aligned} \max_D &amp; \, \mathbb{E}_{x \sim P_r}[D(x)] - \mathbb{E}_{\hat{x} \sim P_g}[D(\hat{x})], \\ \min_G &amp; \, \mathbb{E}_{\hat{x} \sim P_g}[D(\hat{x})]. \end{aligned}\] <h3 id="enforcing-the-1-lipschitz-constraint">Enforcing the 1-Lipschitz Constraint</h3> <p>A critical requirement for the discriminator in WGANs is the 1-Lipschitz constraint. In the original WGAN formulation, this constraint was enforced by clipping the weights of the discriminator to a narrow range. However, this clipping can lead to several practical problems, such as underfitting.</p> <p>An improvement to this approach is the gradient penalty method<d-cite key="gulrajani2017improved"></d-cite>. Here, the 1-Lipschitz constraint is enforced by adding a penalty to the loss function, ensuring that the gradient of the discriminator with respect to its input is close to 1:</p> \[\label{eq:gradient_penalty} \mathcal{L}_{\text{GP}} = \lambda \mathbb{E}_{\hat{x} \sim P_{\hat{x}}}\left[(\|\nabla_{\hat{x}} D(\hat{x})\|_2 - 1)^2\right],\] <p>where \(P_{\hat{x}}\) is the distribution of points along straight lines between pairs of points sampled from \(P_r\) and \(P_g\).</p> <h2 id="conclusion">Conclusion</h2> <p>Wasserstein GANs mark a significant advancement in the field of generative modeling, especially for image synthesis. By addressing the fundamental shortcomings of standard GANs with the imposition of the Wasserstein distance, WGANs achieve more stable training dynamics and generate higher quality samples.</p> <p>The theoretical robustness rooted in optimal transport theory and practical improvements like gradient penalty make WGANs a critical tool in the arsenal of machine learning practitioners. As research in this area progresses, we can expect further refinements and hybrid models that continue to push the boundaries of what generative models can achieve.</p> <p>In subsequent posts, we will explore other transformative advancements in AI and machine learning, providing a comprehensive view of the state-of-the-art technologies shaping our world.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/2024-05-29-wgan.bib"></d-bibliography> <div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"Purdue-BoilMLC/Purdue-BoilMLC.github.io","data-repo-id":"","data-category":"Comments","data-category-id":"","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2024 . Made with ❤ by <a href="https://Purdue-BoilMLC.github.io">Boil-MLC</a>. The source code is licensed <a href="https://github.com/Purdue-BoilMLC/Purdue-BoilMLC.github.io/blob/master/LICENSE" rel="external nofollow noopener" target="_blank">MIT</a>. Last updated: July 17, 2024. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id="></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>