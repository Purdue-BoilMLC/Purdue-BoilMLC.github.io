<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> A brief introduction to Deep Q-Learning | Boilermakers Machine Learning Collaborative (Boil-MLC) | Students Machine Learning Seminar at Purdue University </title> <meta name="author" content=" "> <meta name="description" content="A paper review on &lt;a href=https://arxiv.org/pdf/1701.07875&gt;DQN&lt;/a&gt;"> <meta name="keywords" content="Machine Learning, Interdisciplinary Collaboration, Academic Initiative, PhD Students, Research, Innovation, Workshops, Seminars, Purdue University, Computer Science, Mathematics, Statistics"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/u1f525_u1f95b.png?ccae948c32cbc6d3f1ace744c1e8707b"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://purdue-boilmlc.github.io/blog/2024/DQN/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "A brief introduction to Deep Q-Learning",
            "description": "A paper review on <a href=https://arxiv.org/pdf/1701.07875>DQN</a>",
            "published": "July 05, 2024",
            "authors": [
              
              {
                "author": "Yineng Chen",
                "authorURL": "https://chernyn.github.io/",
                "affiliations": [
                  {
                    "name": "Purdue University",
                    "url": "https://www.purdue.edu"
                  }
                ]
              },
              
              {
                "author": "Yuetian Chen",
                "authorURL": "https://stry233.github.io/",
                "affiliations": [
                  {
                    "name": "TruSeLab, Purdue University",
                    "url": "https://www.cs.purdue.edu/truselab/"
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter abbr-title" href="/"> <img src="/assets/img/u1f525_u1f95b.png" alt="Logo" style="height: 30px; vertical-align: middle; margin-right: 5px; position: relative; top: -2.5px;">Boil-MLC </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Articles </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Events </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">People </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>A brief introduction to Deep Q-Learning</h1> <p>A paper review on <a href="https://arxiv.org/pdf/1701.07875" rel="external nofollow noopener" target="_blank">DQN</a></p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#introduction">Introduction</a> </div> <div> <a href="#scaling-language-models">Scaling Language Models</a> </div> <ul> <li> <a href="#the-gopher-architecture">The Gopher Architecture</a> </li> <li> <a href="#key-insights-from-gopher">Key Insights from Gopher</a> </li> </ul> <div> <a href="#conclusion">Conclusion</a> </div> </nav> </d-contents> <h2 id="introduction">Introduction</h2> <p>This paper proposes a basic end-to-end high-dimensional pixel control strategy based on the reinforcement learning framework of the Q-Learning algorithm in the 1992 paper, combined with the powerful image processing capabilities of convolutional neural networks.</p> <p>The above framework can handle high-dimensional data such as pixels, but the correlation between the data and the instability of data distribution in reinforcement learning itself have not been solved. The author uses the experience replay mechanism to solve this problem based on the 1993 paper 2. This experience replay mechanism hopes that the distribution of reinforcement learning can slowly transition from the random data at the beginning to the current situation with better results.</p> <h2 id="q-learning">Q-Learning</h2> <h3 id="definition">Definition</h3> <ul> <li>Q-function maps state and action pairs to expected reward.</li> <li>For some state $s$ and action $a$, Q-function $Q(s,a)$ represents the expected accumulated reward when the agent choose action $a$ under the state $s$, and follow some policy until the end of the task.</li> <li>If we have an optimal function $Q^{*}(s,a)$, then we can get the largest reward if the agent take action $a$ of the $Q^{*}(s,a)$ under the state of $s$. This is the learning target of Q-Learning.</li> </ul> <h3 id="algorithm-procedure">Algorithm Procedure</h3> <ol> <li>Initialization of the Q function <ul> <li>Represent it by a Q-table or Q-network.</li> <li>Generate the the initial value.</li> </ul> </li> <li>Interation between the agent and the environment. <ul> <li>The agent observes the current state $s_t$.</li> <li>The agent selects an action $a_t$ according to the given policy, like the $\epsilon$-greedy policy.</li> <li>Take action $a_t$, and the environment returns the reward $r_t$ and the next state $s_{t+1}$.</li> <li>Experience $(s_t, a_t, r_t, s_{t+1})$ is restored in the replay pool.</li> </ul> </li> <li>Training <ul> <li>Sample a batch of (s, a, r, s’) in the experience replay pool.</li> <li>Compute target for each experience: \(y = r + \gamma * max_{a'} Q(s', a')\) where \gamma is the discount factor, indicating the importance attached to future rewards</li> <li>compute TD error: \(e = y - Q(s, a)\)</li> <li>Update Q-function based on TD error: \(Q(s, a) &lt;- Q(s, a) + α * e\) where $\alpha$ is the learning rate</li> </ul> </li> <li>Repeat the procedure 2 and 3, until the Q-function converges or when it reaches the given training step.</li> </ol> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/2024-05-29-review.bib"></d-bibliography> <div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"Purdue-BoilMLC/Purdue-BoilMLC.github.io","data-repo-id":"","data-category":"General","data-category-id":"","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2024 . Made with ❤ by <a href="https://Purdue-BoilMLC.github.io">Boil-MLC</a>. The source code is licensed <a href="https://github.com/Purdue-BoilMLC/Purdue-BoilMLC.github.io/blob/master/LICENSE" rel="external nofollow noopener" target="_blank">MIT</a>. Last updated: July 24, 2024. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-K5X43VBBDE"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-K5X43VBBDE");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>