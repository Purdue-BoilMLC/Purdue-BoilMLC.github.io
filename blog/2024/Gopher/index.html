<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Gopher: Scaling Language Models to New Heights | Boilermakers Machine Learning Collaborative (Boil-MLC) | Students Machine Learning Seminar at Purdue University </title> <meta name="author" content=" "> <meta name="description" content="A paper review on &lt;a href=https://arxiv.org/pdf/2112.11446&gt;Scaling Language Models: Methods, Analysis &amp; Insights from Training Gopher&lt;/a&gt;"> <meta name="keywords" content="Machine Learning, Interdisciplinary Collaboration, Academic Initiative, PhD Students, Research, Innovation, Workshops, Seminars, Purdue University, Computer Science, Mathematics, Statistics"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/u1f525_u1f95b.png?ccae948c32cbc6d3f1ace744c1e8707b"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://purdue-boilmlc.github.io/blog/2024/Gopher/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Gopher: Scaling Language Models to New Heights",
            "description": "A paper review on <a href=https://arxiv.org/pdf/2112.11446>Scaling Language Models: Methods, Analysis & Insights from Training Gopher</a>",
            "published": "May 29, 2024",
            "authors": [
              
              {
                "author": "Yuetian Chen",
                "authorURL": "https://stry233.github.io/",
                "affiliations": [
                  {
                    "name": "TruSeLab, Purdue University",
                    "url": "https://www.cs.purdue.edu/truselab/"
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter abbr-title" href="/"> <img src="/assets/img/u1f525_u1f95b.png" alt="Logo" style="height: 30px; vertical-align: middle; margin-right: 5px; position: relative; top: -2.5px;">Boil-MLC </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Articles </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Events </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">People </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Gopher: Scaling Language Models to New Heights</h1> <p>A paper review on <a href="https://arxiv.org/pdf/2112.11446" rel="external nofollow noopener" target="_blank">Scaling Language Models: Methods, Analysis &amp; Insights from Training Gopher</a></p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#introduction">Introduction</a> </div> <div> <a href="#scaling-language-models">Scaling Language Models</a> </div> <ul> <li> <a href="#the-gopher-architecture">The Gopher Architecture</a> </li> <li> <a href="#key-insights-from-gopher">Key Insights from Gopher</a> </li> </ul> <div> <a href="#conclusion">Conclusion</a> </div> </nav> </d-contents> <h2 id="introduction">Introduction</h2> <p>Recent years have seen tremendous progress in the fields of natural language processing (NLP) and generative modeling. Language models like GPT-3<d-cite key="brown2020language"></d-cite> and PaLM<d-cite key="chowdhery2022palm"></d-cite> have demonstrated remarkable capabilities in understanding and generating human-like text. In this blog post, we delve into the groundbreaking work on the Gopher model<d-cite key="rae2022scaling"></d-cite> developed by DeepMind. We will explore the architecture, key insights from this work, and its implications for the future of language models.</p> <h2 id="scaling-language-models">Scaling Language Models</h2> <p>Language models form the backbone of modern NLP systems. By learning from vast corpora of text data, these models acquire a broad understanding of language that can be applied to diverse downstream tasks. The Gopher model<d-cite key="rae2022scaling"></d-cite>, developed by DeepMind, represents an important milestone in the scaling of language models.</p> <h3 id="the-gopher-architecture">The Gopher Architecture</h3> <p>Gopher is a large-scale transformer-based language model. It follows the decoder-only architecture that has become standard for models like GPT-3. However, the Gopher architecture incorporates several notable and innovative modifications which distinguish it from its predecessors:</p> <ol> <li> <p><strong>Scaling in Size</strong>: Gopher ranges up to 280 billion parameters, significantly larger than many previous models. This increase in scale aims to leverage more data and model capacity to improve performance across diverse tasks.</p> </li> <li> <p><strong>RMSNorm instead of LayerNorm</strong>: Gopher employs RMSNorm<d-cite key="zhang2019root"></d-cite> instead of the more commonly used LayerNorm. RMSNorm (Root Mean Square Normalization) is computationally simpler and may lead to more stable gradients, enhancing the performance of deep networks. Mathematically, RMSNorm normalizes the inputs based on their root mean square, promoting better normalization properties by focusing on the scale of the neurons’ activations.</p> \[\text{RMSNorm}(\mathbf{x}) = \frac{\mathbf{x}}{\text{RMS}(\mathbf{x})}\] <p>where \(\text{RMS}(\mathbf{x}) = \sqrt{\frac{1}{d} \sum_{i=1}^{d} x_i^2}\), and \(d\) is the dimension of the input vector \(\mathbf{x}\).</p> </li> <li> <p><strong>Relative Positional Encodings</strong>: Gopher utilizes relative positional encodings instead of absolute positional encodings. This method allows the model to better capture the relative distances and dependencies between tokens within the input sequence. Relative positional encodings maintain consistent performance regardless of the sequence length.</p> </li> </ol> <h3 id="key-insights-from-gopher">Key Insights from Gopher</h3> <p>The Gopher paper offers several valuable insights into the behavior and benefits of scaling up language models:</p> <ol> <li> <p><strong>Task Performance</strong>: The benefits of scale are most pronounced on tasks such as reading comprehension, fact-checking, and toxicity detection. The improvements in logical and mathematical reasoning are more modest. This discrepancy can be attributed to the nature and distribution of training data, highlighting the importance of dataset curation for developing balanced and effective language models.</p> </li> <li> <p><strong>Generalization</strong>: Larger models like Gopher generalize better across a diverse set of tasks. They demonstrate enhanced zero-shot and few-shot learning capabilities, where the model has to perform tasks with minimal or no task-specific training data.</p> </li> <li> <p><strong>Ethical Considerations</strong>: As models scale, ethical and societal implications become more significant. The Gopher paper emphasizes the need for comprehensive evaluations of model biases and the importance of developing frameworks for responsible AI.</p> </li> </ol> <p>The Gopher model underscores the immense potential of scaling up language models in terms of parameter size and data volume. It points to a future where such models can serve as flexible, general-purpose tools for a wide range of applications.</p> <h2 id="conclusion">Conclusion</h2> <p>Gopher represents a significant advancement in the field of language modeling, pushing the boundaries of what large-scale models can achieve. Its novel architectural choices and insightful analysis provide a valuable blueprint for future research and development in NLP. As we continue to scale up models and refine our training techniques, we will unlock new frontiers in machine intelligence, transforming the capabilities of AI systems across various domains. However, it is crucial to address the ethical and societal implications of these powerful technologies, ensuring their development and deployment benefit all of humanity.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/2024-05-29-gopher.bib"></d-bibliography> <div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"Purdue-BoilMLC/Purdue-BoilMLC.github.io","data-repo-id":"","data-category":"Comments","data-category-id":"","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2024 . Made with ❤ by <a href="https://Purdue-BoilMLC.github.io">Boil-MLC</a>. The source code is licensed <a href="https://github.com/Purdue-BoilMLC/Purdue-BoilMLC.github.io/blob/master/LICENSE" rel="external nofollow noopener" target="_blank">MIT</a>. Last updated: July 24, 2024. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-K5X43VBBDE"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-K5X43VBBDE");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>